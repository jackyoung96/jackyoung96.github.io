{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX\n",
    "\n",
    "<img width=\"758\" alt=\"image\" src=\"https://user-images.githubusercontent.com/57203764/197336149-82d68617-8fff-4216-b457-6f828a861bd7.png\">\n",
    "\n",
    "학습된 model을 ONNX 모델로 만들어준 후, inference 할 때 사용자가 원하는 framework를 사용할 수 있도록 만들어주는 과정을 model packaging 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX packaging\n",
    "\n",
    "PyTorch 버전과 PyTorch-lightning 버전이 있다. (나는 PyTorch 버전을 더 많이 사용하지 않을까 싶다!)\n",
    "\n",
    "필요한 것은 \n",
    "- Name of the onnx model\n",
    "- Input sample\n",
    "- Input names (초기 input 뿐만 아니라 각 layer의 input들까지 이름을 지정해 줄 수 있다. layer input의 개수보다 적을 시에는 남는 것은 자동으로 이름 붙여진다.)\n",
    "- Output names (output의 이름)\n",
    "- Dynamic axes (각 input들에서 변하도록 설계된 axes를 표시해 주는 것. 일반적으로는 batch인 0번 axis 혹은 RNN의 sequence length 정도가 되겠다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install pytorch_lightning torch transformers datasets sklearn torchmetrics wandb matplotlib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name) # Transformer (BERT) model\n",
    "\n",
    "    def prepare_data(self):\n",
    "        cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "        self.train_data = cola_dataset[\"train\"]\n",
    "        self.val_data = cola_dataset[\"validation\"]\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        # processing the data\n",
    "        return self.tokenizer(\n",
    "            example[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_data = self.train_data.map(self.tokenize_data, batched=True)\n",
    "            self.train_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "            self.val_data = self.val_data.map(self.tokenize_data, batched=True)\n",
    "            self.val_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"],\n",
    "                output_all_columns=True,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaModel(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", lr=1e-2):\n",
    "        super(ColaModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.num_classes = 2\n",
    "\n",
    "        self.train_accuracy_metric = torchmetrics.Accuracy()\n",
    "        self.val_accuracy_metric = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        h_cls = outputs.last_hidden_state[:, 0]\n",
    "        logits = self.W(h_cls)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\n",
    "\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        train_acc = self.train_accuracy_metric(preds, batch[\"label\"])\n",
    "        self.log(\"train/loss\", loss.detach().cpu(), prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train/accuracy\", train_acc.detach().cpu(), prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        val_acc = self.val_accuracy_metric(preds, batch[\"label\"])\n",
    "        self.log(\"val/loss\", loss.detach().cpu(), prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val/acc\", val_acc.detach().cpu(), prog_bar=True, on_epoch=True)\n",
    "        return {\"labels\": batch[\"label\"], \"logits\": logits}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        labels = torch.cat([x[\"labels\"] for x in outputs])\n",
    "        logits = torch.cat([x[\"logits\"] for x in outputs])\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        data = confusion_matrix(labels, preds)\n",
    "        df_cm = pd.DataFrame(data, columns=np.unique(labels), index=np.unique(labels))\n",
    "        df_cm.index.name = \"Actual\"\n",
    "        df_cm.columns.name = \"Predicted\"\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        plot = sns.heatmap(\n",
    "            df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}\n",
    "        )  # font size\n",
    "        self.logger.experiment.log({\"Confusion Matrix\": wandb.Image(plot)})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Found cached dataset glue (/home/jaekyungcho/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 803.30it/s]\n",
      "Loading cached processed dataset at /home/jaekyungcho/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-69164c84e67edcff.arrow\n",
      "100%|██████████| 2/2 [00:00<00:00, 18.58ba/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"models/best-checkpoint.ckpt\"\n",
    "cola_model = ColaModel.load_from_checkpoint(model_path)\n",
    "data_model = DataModule()\n",
    "data_model.prepare_data()\n",
    "data_model.setup()\n",
    "\n",
    "input_batch = next(iter(data_model.train_dataloader()))\n",
    "input_sample = {\n",
    "    \"input_ids\": input_batch[\"input_ids\"][0].unsqueeze(0),\n",
    "    \"attention_mask\": input_batch[\"attention_mask\"][0].unsqueeze(0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input_ids : Long(*, 256, strides=[256, 1], requires_grad=0, device=cpu),\n",
      "      %attention_mask : Long(*, 256, strides=[256, 1], requires_grad=0, device=cpu),\n",
      "      %bert.embeddings.position_ids : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %bert.embeddings.word_embeddings.weight : Float(30522, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %bert.embeddings.position_embeddings.weight : Float(512, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %bert.embeddings.token_type_embeddings.weight : Float(2, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %bert.embeddings.LayerNorm.weight : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.embeddings.LayerNorm.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.self.query.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.self.key.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.self.value.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.output.dense.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.output.LayerNorm.weight : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.attention.output.LayerNorm.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.intermediate.dense.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.output.dense.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.output.LayerNorm.weight : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.0.output.LayerNorm.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.self.query.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.self.key.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.self.value.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.output.dense.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.output.LayerNorm.weight : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.attention.output.LayerNorm.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.intermediate.dense.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.output.dense.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.output.LayerNorm.weight : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bert.encoder.layer.1.output.LayerNorm.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %W.weight : Float(2, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %W.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Slice_334 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Slice_335 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_338 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_339 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::Concat_340 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Concat_341 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_342 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::Concat_347 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_348 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_349 : Float(128, 512, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_350 : Float(512, 128, strides=[1, 512], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_351 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_352 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_355 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_361 : Float(128, 128, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_362 : Float(128, 512, strides=[1, 128], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_363 : Float(512, 128, strides=[1, 512], requires_grad=0, device=cpu)):\n",
      "  %onnx::Concat_360 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_0\"](%onnx::Concat_347)\n",
      "  %onnx::Concat_359 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_1\"](%onnx::Concat_341)\n",
      "  %onnx::Concat_358 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_2\"](%onnx::Concat_340)\n",
      "  %onnx::Concat_357 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_3\"](%onnx::Concat_341)\n",
      "  %onnx::Concat_356 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_4\"](%onnx::Concat_340)\n",
      "  %onnx::Concat_354 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_5\"](%onnx::Concat_341)\n",
      "  %onnx::Concat_353 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_6\"](%onnx::Concat_340)\n",
      "  %onnx::Concat_346 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_7\"](%onnx::Concat_341)\n",
      "  %onnx::Concat_345 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_8\"](%onnx::Concat_340)\n",
      "  %onnx::Concat_344 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_9\"](%onnx::Concat_341)\n",
      "  %onnx::Concat_343 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_10\"](%onnx::Concat_340)\n",
      "  %onnx::Slice_337 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_11\"](%onnx::Slice_335)\n",
      "  %onnx::Slice_336 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity[onnx_name=\"Identity_12\"](%onnx::Slice_334)\n",
      "  %onnx::Gather_44 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_13\"](%input_ids) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Gather_45 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_14\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Unsqueeze_46 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_15\"](%onnx::Gather_44, %onnx::Gather_45) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Gather_47 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_16\"](%input_ids) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Gather_48 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_17\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Unsqueeze_49 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_18\"](%onnx::Gather_47, %onnx::Gather_48) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:962:0\n",
      "  %onnx::Slice_50 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"Constant_19\"]()\n",
      "  %onnx::Slice_54 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_20\"](%onnx::Unsqueeze_49) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:979:0\n",
      "  %onnx::Slice_56 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_21\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:979:0\n",
      "  %onnx::Expand_57 : Long(*, *, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"Slice_22\"](%onnx::Slice_50, %onnx::Slice_334, %onnx::Slice_54, %onnx::Slice_335, %onnx::Slice_56) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:979:0\n",
      "  %onnx::Concat_58 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_23\"](%onnx::Unsqueeze_46) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Concat_59 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_24\"](%onnx::Unsqueeze_49) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Reshape_60 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_25\"](%onnx::Concat_58, %onnx::Concat_59) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Reshape_61 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"Constant_26\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Shape_62 : Long(2, strides=[1], device=cpu) = onnx::Reshape[onnx_name=\"Reshape_27\"](%onnx::Reshape_60, %onnx::Reshape_61) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::ConstantOfShape_63 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_28\"](%onnx::Shape_62) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Mul_64 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"ConstantOfShape_29\"](%onnx::ConstantOfShape_63) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Mul_65 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"Constant_30\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Equal_66 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"Mul_31\"](%onnx::Mul_64, %onnx::Mul_65) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Where_67 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"Equal_32\"](%onnx::Shape_62, %onnx::Equal_66) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Expand_68 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"Where_33\"](%onnx::Where_67, %onnx::Mul_64, %onnx::Shape_62) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %input : Long(*, *, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"Expand_34\"](%onnx::Expand_57, %onnx::Expand_68) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:980:0\n",
      "  %onnx::Unsqueeze_70 : Long(*, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[1], onnx_name=\"Unsqueeze_35\"](%attention_mask) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/modeling_utils.py:779:0\n",
      "  %onnx::Cast_71 : Long(*, 1, 1, 256, strides=[256, 256, 256, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"Unsqueeze_36\"](%onnx::Unsqueeze_70) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/modeling_utils.py:779:0\n",
      "  %onnx::Sub_72 : Float(*, 1, 1, 256, strides=[256, 256, 256, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"Cast_37\"](%onnx::Cast_71) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/modeling_utils.py:790:0\n",
      "  %onnx::Sub_73 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_38\"]()\n",
      "  %onnx::Mul_74 : Float(*, 1, 1, 256, strides=[256, 256, 256, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"Sub_39\"](%onnx::Sub_73, %onnx::Sub_72) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/_tensor.py:639:0\n",
      "  %onnx::Mul_75 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-3.40282e+38}, onnx_name=\"Constant_40\"]()\n",
      "  %onnx::Add_76 : Float(*, 1, 1, 256, strides=[256, 256, 256, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"Mul_41\"](%onnx::Mul_74, %onnx::Mul_75) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/modeling_utils.py:791:0\n",
      "  %onnx::Gather_77 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_42\"](%input_ids) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:210:0\n",
      "  %onnx::Gather_78 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_43\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:210:0\n",
      "  %onnx::Unsqueeze_79 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_44\"](%onnx::Gather_77, %onnx::Gather_78) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:210:0\n",
      "  %onnx::Slice_83 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_45\"](%onnx::Unsqueeze_79) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:217:0\n",
      "  %onnx::Slice_85 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_46\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:217:0\n",
      "  %input.4 : Long(*, *, strides=[512, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"Slice_47\"](%bert.embeddings.position_ids, %onnx::Slice_336, %onnx::Slice_83, %onnx::Slice_337, %onnx::Slice_85) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:217:0\n",
      "  %onnx::Add_87 : Float(*, 256, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Gather[onnx_name=\"Gather_48\"](%bert.embeddings.word_embeddings.weight, %input_ids) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2199:0\n",
      "  %onnx::Add_88 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Gather[onnx_name=\"Gather_49\"](%bert.embeddings.token_type_embeddings.weight, %input) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2199:0\n",
      "  %onnx::Add_89 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_50\"](%onnx::Add_87, %onnx::Add_88) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:234:0\n",
      "  %onnx::Add_90 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Gather[onnx_name=\"Gather_51\"](%bert.embeddings.position_embeddings.weight, %input.4) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2199:0\n",
      "  %onnx::ReduceMean_91 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_52\"](%onnx::Add_89, %onnx::Add_90) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:237:0\n",
      "  %onnx::Sub_92 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_53\"](%onnx::ReduceMean_91) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_93 : Float(*, *, 128, device=cpu) = onnx::Sub[onnx_name=\"Sub_54\"](%onnx::ReduceMean_91, %onnx::Sub_92) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_94 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"Constant_55\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::ReduceMean_95 : Float(*, *, 128, device=cpu) = onnx::Pow[onnx_name=\"Pow_56\"](%onnx::Pow_93, %onnx::Pow_94) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_96 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_57\"](%onnx::ReduceMean_95) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_97 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}, onnx_name=\"Constant_58\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Sqrt_98 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name=\"Add_59\"](%onnx::Add_96, %onnx::Add_97) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Div_99 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"Sqrt_60\"](%onnx::Sqrt_98) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Mul_100 : Float(*, *, 128, device=cpu) = onnx::Div[onnx_name=\"Div_61\"](%onnx::Pow_93, %onnx::Div_99) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_101 : Float(*, *, 128, device=cpu) = onnx::Mul[onnx_name=\"Mul_62\"](%onnx::Mul_100, %bert.embeddings.LayerNorm.weight) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %input.8 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_63\"](%onnx::Add_101, %bert.embeddings.LayerNorm.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_104 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_64\"](%input.8, %onnx::MatMul_338) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %mixed_query_layer : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_65\"](%bert.encoder.layer.0.attention.self.query.bias, %onnx::Add_104) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Add_107 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_66\"](%input.8, %onnx::MatMul_339) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Shape_108 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_67\"](%bert.encoder.layer.0.attention.self.key.bias, %onnx::Add_107) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Gather_109 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_68\"](%onnx::Shape_108) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_110 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_69\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_111 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_70\"](%onnx::Gather_109, %onnx::Gather_110) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_112 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_71\"](%onnx::Shape_108) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_113 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_72\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_114 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_73\"](%onnx::Gather_112, %onnx::Gather_113) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_117 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_74\"](%onnx::Unsqueeze_111)\n",
      "  %onnx::Concat_118 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_75\"](%onnx::Unsqueeze_114)\n",
      "  %onnx::Reshape_121 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_76\"](%onnx::Concat_117, %onnx::Concat_118, %onnx::Concat_340, %onnx::Concat_341) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_122 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_77\"](%onnx::Shape_108, %onnx::Reshape_121) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Add_124 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_78\"](%input.8, %onnx::MatMul_342) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Shape_125 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_79\"](%bert.encoder.layer.0.attention.self.value.bias, %onnx::Add_124) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Gather_126 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_80\"](%onnx::Shape_125) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_127 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_81\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_128 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_82\"](%onnx::Gather_126, %onnx::Gather_127) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_129 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_83\"](%onnx::Shape_125) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_130 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_84\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_131 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_85\"](%onnx::Gather_129, %onnx::Gather_130) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_134 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_86\"](%onnx::Unsqueeze_128)\n",
      "  %onnx::Concat_135 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_87\"](%onnx::Unsqueeze_131)\n",
      "  %onnx::Reshape_138 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_88\"](%onnx::Concat_134, %onnx::Concat_135, %onnx::Concat_343, %onnx::Concat_344) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_139 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_89\"](%onnx::Shape_125, %onnx::Reshape_138) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::MatMul_140 : Float(*, 2, *, 64, strides=[32768, 64, 128, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_90\"](%onnx::Transpose_139) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:273:0\n",
      "  %onnx::Gather_141 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_91\"](%mixed_query_layer) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_142 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_92\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_143 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_93\"](%onnx::Gather_141, %onnx::Gather_142) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_144 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_94\"](%mixed_query_layer) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_145 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_95\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_146 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_96\"](%onnx::Gather_144, %onnx::Gather_145) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_149 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_97\"](%onnx::Unsqueeze_143)\n",
      "  %onnx::Concat_150 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_98\"](%onnx::Unsqueeze_146)\n",
      "  %onnx::Reshape_153 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_99\"](%onnx::Concat_149, %onnx::Concat_150, %onnx::Concat_345, %onnx::Concat_346) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_154 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_100\"](%mixed_query_layer, %onnx::Reshape_153) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::MatMul_155 : Float(*, 2, *, 64, strides=[32768, 64, 128, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_101\"](%onnx::Transpose_154) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:273:0\n",
      "  %onnx::MatMul_156 : Float(*, 2, 64, *, strides=[32768, 64, 1, 128], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"Transpose_102\"](%onnx::Transpose_122) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:323:0\n",
      "  %onnx::Div_157 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_103\"](%onnx::MatMul_155, %onnx::MatMul_156) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:323:0\n",
      "  %onnx::Div_158 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"Constant_104\"]()\n",
      "  %onnx::Add_159 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"Div_105\"](%onnx::Div_157, %onnx::Div_158) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:341:0\n",
      "  %attention_scores : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_106\"](%onnx::Add_159, %onnx::Add_76) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:344:0\n",
      "  %input.12 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3, onnx_name=\"Softmax_107\"](%attention_scores) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:1834:0\n",
      "  %onnx::Transpose_162 : Float(*, 2, *, 64, strides=[32768, 16384, 64, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_108\"](%input.12, %onnx::MatMul_140) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:357:0\n",
      "  %onnx::Shape_163 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_109\"](%onnx::Transpose_162) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:359:0\n",
      "  %onnx::Gather_164 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_110\"](%onnx::Shape_163) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_165 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_111\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Unsqueeze_166 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_112\"](%onnx::Gather_164, %onnx::Gather_165) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_167 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_113\"](%onnx::Shape_163) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_168 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_114\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Unsqueeze_169 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_115\"](%onnx::Gather_167, %onnx::Gather_168) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Concat_171 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_116\"](%onnx::Unsqueeze_166)\n",
      "  %onnx::Concat_172 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_117\"](%onnx::Unsqueeze_169)\n",
      "  %onnx::Reshape_174 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_118\"](%onnx::Concat_171, %onnx::Concat_172, %onnx::Concat_347) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:361:0\n",
      "  %onnx::MatMul_175 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_119\"](%onnx::Shape_163, %onnx::Reshape_174) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:361:0\n",
      "  %onnx::Add_177 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_120\"](%onnx::MatMul_175, %onnx::MatMul_348) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.16 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_121\"](%bert.encoder.layer.0.attention.output.dense.bias, %onnx::Add_177) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.20 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_122\"](%input.16, %input.8) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:380:0\n",
      "  %onnx::Sub_180 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_123\"](%input.20) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_181 : Float(*, *, 128, device=cpu) = onnx::Sub[onnx_name=\"Sub_124\"](%input.20, %onnx::Sub_180) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_182 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"Constant_125\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::ReduceMean_183 : Float(*, *, 128, device=cpu) = onnx::Pow[onnx_name=\"Pow_126\"](%onnx::Pow_181, %onnx::Pow_182) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_184 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_127\"](%onnx::ReduceMean_183) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_185 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}, onnx_name=\"Constant_128\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Sqrt_186 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name=\"Add_129\"](%onnx::Add_184, %onnx::Add_185) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Div_187 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"Sqrt_130\"](%onnx::Sqrt_186) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Mul_188 : Float(*, *, 128, device=cpu) = onnx::Div[onnx_name=\"Div_131\"](%onnx::Pow_181, %onnx::Div_187) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_189 : Float(*, *, 128, device=cpu) = onnx::Mul[onnx_name=\"Mul_132\"](%onnx::Mul_188, %bert.encoder.layer.0.attention.output.LayerNorm.weight) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::MatMul_190 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_133\"](%onnx::Add_189, %bert.encoder.layer.0.attention.output.LayerNorm.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_192 : Float(*, *, 512, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_134\"](%onnx::MatMul_190, %onnx::MatMul_349) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Div_193 : Float(*, *, 512, strides=[131072, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_135\"](%bert.encoder.layer.0.intermediate.dense.bias, %onnx::Add_192) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Div_194 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"Constant_136\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Erf_195 : Float(*, *, 512, device=cpu) = onnx::Div[onnx_name=\"Div_137\"](%onnx::Div_193, %onnx::Div_194) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_196 : Float(*, *, 512, device=cpu) = onnx::Erf[onnx_name=\"Erf_138\"](%onnx::Erf_195) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_197 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_139\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_198 : Float(*, *, 512, device=cpu) = onnx::Add[onnx_name=\"Add_140\"](%onnx::Add_196, %onnx::Add_197) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_199 : Float(*, *, 512, device=cpu) = onnx::Mul[onnx_name=\"Mul_141\"](%onnx::Div_193, %onnx::Mul_198) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_200 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"Constant_142\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::MatMul_201 : Float(*, *, 512, strides=[131072, 512, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"Mul_143\"](%onnx::Mul_199, %onnx::Mul_200) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_203 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_144\"](%onnx::MatMul_201, %onnx::MatMul_350) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.24 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_145\"](%bert.encoder.layer.0.output.dense.bias, %onnx::Add_203) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.28 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_146\"](%input.24, %onnx::MatMul_190) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:458:0\n",
      "  %onnx::Sub_206 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_147\"](%input.28) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_207 : Float(*, *, 128, device=cpu) = onnx::Sub[onnx_name=\"Sub_148\"](%input.28, %onnx::Sub_206) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_208 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"Constant_149\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::ReduceMean_209 : Float(*, *, 128, device=cpu) = onnx::Pow[onnx_name=\"Pow_150\"](%onnx::Pow_207, %onnx::Pow_208) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_210 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_151\"](%onnx::ReduceMean_209) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_211 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}, onnx_name=\"Constant_152\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Sqrt_212 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name=\"Add_153\"](%onnx::Add_210, %onnx::Add_211) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Div_213 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"Sqrt_154\"](%onnx::Sqrt_212) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Mul_214 : Float(*, *, 128, device=cpu) = onnx::Div[onnx_name=\"Div_155\"](%onnx::Pow_207, %onnx::Div_213) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_215 : Float(*, *, 128, device=cpu) = onnx::Mul[onnx_name=\"Mul_156\"](%onnx::Mul_214, %bert.encoder.layer.0.output.LayerNorm.weight) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::MatMul_216 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_157\"](%onnx::Add_215, %bert.encoder.layer.0.output.LayerNorm.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_218 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_158\"](%onnx::MatMul_216, %onnx::MatMul_351) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %mixed_query_layer.3 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_159\"](%bert.encoder.layer.1.attention.self.query.bias, %onnx::Add_218) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Add_221 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_160\"](%onnx::MatMul_216, %onnx::MatMul_352) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Shape_222 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_161\"](%bert.encoder.layer.1.attention.self.key.bias, %onnx::Add_221) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Gather_223 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_162\"](%onnx::Shape_222) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_224 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_163\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_225 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_164\"](%onnx::Gather_223, %onnx::Gather_224) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_226 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_165\"](%onnx::Shape_222) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_227 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_166\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_228 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_167\"](%onnx::Gather_226, %onnx::Gather_227) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_231 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_168\"](%onnx::Unsqueeze_225)\n",
      "  %onnx::Concat_232 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_169\"](%onnx::Unsqueeze_228)\n",
      "  %onnx::Reshape_235 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_170\"](%onnx::Concat_231, %onnx::Concat_232, %onnx::Concat_353, %onnx::Concat_354) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_236 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_171\"](%onnx::Shape_222, %onnx::Reshape_235) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Add_238 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_172\"](%onnx::MatMul_216, %onnx::MatMul_355) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Shape_239 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_173\"](%bert.encoder.layer.1.attention.self.value.bias, %onnx::Add_238) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Gather_240 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_174\"](%onnx::Shape_239) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_241 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_175\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_242 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_176\"](%onnx::Gather_240, %onnx::Gather_241) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_243 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_177\"](%onnx::Shape_239) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_244 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_178\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_245 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_179\"](%onnx::Gather_243, %onnx::Gather_244) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_248 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_180\"](%onnx::Unsqueeze_242)\n",
      "  %onnx::Concat_249 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_181\"](%onnx::Unsqueeze_245)\n",
      "  %onnx::Reshape_252 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_182\"](%onnx::Concat_248, %onnx::Concat_249, %onnx::Concat_356, %onnx::Concat_357) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_253 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_183\"](%onnx::Shape_239, %onnx::Reshape_252) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::MatMul_254 : Float(*, 2, *, 64, strides=[32768, 64, 128, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_184\"](%onnx::Transpose_253) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:273:0\n",
      "  %onnx::Gather_255 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_185\"](%mixed_query_layer.3) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_256 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_186\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_257 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_187\"](%onnx::Gather_255, %onnx::Gather_256) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_258 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_188\"](%mixed_query_layer.3) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Gather_259 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_189\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Unsqueeze_260 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_190\"](%onnx::Gather_258, %onnx::Gather_259) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:271:0\n",
      "  %onnx::Concat_263 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_191\"](%onnx::Unsqueeze_257)\n",
      "  %onnx::Concat_264 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_192\"](%onnx::Unsqueeze_260)\n",
      "  %onnx::Reshape_267 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_193\"](%onnx::Concat_263, %onnx::Concat_264, %onnx::Concat_358, %onnx::Concat_359) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::Transpose_268 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_194\"](%mixed_query_layer.3, %onnx::Reshape_267) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:272:0\n",
      "  %onnx::MatMul_269 : Float(*, 2, *, 64, strides=[32768, 64, 128, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_195\"](%onnx::Transpose_268) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:273:0\n",
      "  %onnx::MatMul_270 : Float(*, 2, 64, *, strides=[32768, 64, 1, 128], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"Transpose_196\"](%onnx::Transpose_236) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:323:0\n",
      "  %onnx::Div_271 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_197\"](%onnx::MatMul_269, %onnx::MatMul_270) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:323:0\n",
      "  %onnx::Div_272 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"Constant_198\"]()\n",
      "  %onnx::Add_273 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"Div_199\"](%onnx::Div_271, %onnx::Div_272) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:341:0\n",
      "  %attention_scores.3 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_200\"](%onnx::Add_273, %onnx::Add_76) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:344:0\n",
      "  %input.32 : Float(*, 2, *, *, strides=[131072, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3, onnx_name=\"Softmax_201\"](%attention_scores.3) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:1834:0\n",
      "  %onnx::Transpose_276 : Float(*, 2, *, 64, strides=[32768, 16384, 64, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_202\"](%input.32, %onnx::MatMul_254) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:357:0\n",
      "  %onnx::Shape_277 : Float(*, *, 2, 64, strides=[32768, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"Transpose_203\"](%onnx::Transpose_276) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:359:0\n",
      "  %onnx::Gather_278 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_204\"](%onnx::Shape_277) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_279 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_205\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Unsqueeze_280 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_206\"](%onnx::Gather_278, %onnx::Gather_279) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_281 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"Shape_207\"](%onnx::Shape_277) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Gather_282 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_208\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Unsqueeze_283 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"Gather_209\"](%onnx::Gather_281, %onnx::Gather_282) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:360:0\n",
      "  %onnx::Concat_285 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_210\"](%onnx::Unsqueeze_280)\n",
      "  %onnx::Concat_286 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0], onnx_name=\"Unsqueeze_211\"](%onnx::Unsqueeze_283)\n",
      "  %onnx::Reshape_288 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"Concat_212\"](%onnx::Concat_285, %onnx::Concat_286, %onnx::Concat_360) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:361:0\n",
      "  %onnx::MatMul_289 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_213\"](%onnx::Shape_277, %onnx::Reshape_288) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:361:0\n",
      "  %onnx::Add_291 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_214\"](%onnx::MatMul_289, %onnx::MatMul_361) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.36 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_215\"](%bert.encoder.layer.1.attention.output.dense.bias, %onnx::Add_291) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.40 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_216\"](%input.36, %onnx::MatMul_216) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:380:0\n",
      "  %onnx::Sub_294 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_217\"](%input.40) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_295 : Float(*, *, 128, device=cpu) = onnx::Sub[onnx_name=\"Sub_218\"](%input.40, %onnx::Sub_294) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_296 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"Constant_219\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::ReduceMean_297 : Float(*, *, 128, device=cpu) = onnx::Pow[onnx_name=\"Pow_220\"](%onnx::Pow_295, %onnx::Pow_296) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_298 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_221\"](%onnx::ReduceMean_297) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_299 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}, onnx_name=\"Constant_222\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Sqrt_300 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name=\"Add_223\"](%onnx::Add_298, %onnx::Add_299) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Div_301 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"Sqrt_224\"](%onnx::Sqrt_300) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Mul_302 : Float(*, *, 128, device=cpu) = onnx::Div[onnx_name=\"Div_225\"](%onnx::Pow_295, %onnx::Div_301) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_303 : Float(*, *, 128, device=cpu) = onnx::Mul[onnx_name=\"Mul_226\"](%onnx::Mul_302, %bert.encoder.layer.1.attention.output.LayerNorm.weight) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::MatMul_304 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_227\"](%onnx::Add_303, %bert.encoder.layer.1.attention.output.LayerNorm.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_306 : Float(*, *, 512, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_228\"](%onnx::MatMul_304, %onnx::MatMul_362) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Div_307 : Float(*, *, 512, strides=[131072, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_229\"](%bert.encoder.layer.1.intermediate.dense.bias, %onnx::Add_306) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %onnx::Div_308 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"Constant_230\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Erf_309 : Float(*, *, 512, device=cpu) = onnx::Div[onnx_name=\"Div_231\"](%onnx::Div_307, %onnx::Div_308) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_310 : Float(*, *, 512, device=cpu) = onnx::Erf[onnx_name=\"Erf_232\"](%onnx::Erf_309) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_311 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_233\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_312 : Float(*, *, 512, device=cpu) = onnx::Add[onnx_name=\"Add_234\"](%onnx::Add_310, %onnx::Add_311) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_313 : Float(*, *, 512, device=cpu) = onnx::Mul[onnx_name=\"Mul_235\"](%onnx::Div_307, %onnx::Mul_312) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Mul_314 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"Constant_236\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::MatMul_315 : Float(*, *, 512, strides=[131072, 512, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"Mul_237\"](%onnx::Mul_313, %onnx::Mul_314) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/activations.py:56:0\n",
      "  %onnx::Add_317 : Float(*, *, 128, device=cpu) = onnx::MatMul[onnx_name=\"MatMul_238\"](%onnx::MatMul_315, %onnx::MatMul_363) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.44 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_239\"](%bert.encoder.layer.1.output.dense.bias, %onnx::Add_317) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %input.48 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_240\"](%input.44, %onnx::MatMul_304) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:458:0\n",
      "  %onnx::Sub_320 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_241\"](%input.48) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_321 : Float(*, *, 128, device=cpu) = onnx::Sub[onnx_name=\"Sub_242\"](%input.48, %onnx::Sub_320) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Pow_322 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"Constant_243\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::ReduceMean_323 : Float(*, *, 128, device=cpu) = onnx::Pow[onnx_name=\"Pow_244\"](%onnx::Pow_321, %onnx::Pow_322) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_324 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"ReduceMean_245\"](%onnx::ReduceMean_323) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_325 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}, onnx_name=\"Constant_246\"]() # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Sqrt_326 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name=\"Add_247\"](%onnx::Add_324, %onnx::Add_325) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Div_327 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"Sqrt_248\"](%onnx::Sqrt_326) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Mul_328 : Float(*, *, 128, device=cpu) = onnx::Div[onnx_name=\"Div_249\"](%onnx::Pow_321, %onnx::Div_327) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Add_329 : Float(*, *, 128, device=cpu) = onnx::Mul[onnx_name=\"Mul_250\"](%onnx::Mul_328, %bert.encoder.layer.1.output.LayerNorm.weight) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Gather_330 : Float(*, *, 128, strides=[32768, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"Add_251\"](%onnx::Add_329, %bert.encoder.layer.1.output.LayerNorm.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/functional.py:2503:0\n",
      "  %onnx::Gather_331 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"Constant_252\"]() # /tmp/ipykernel_18824/3039239234.py:16:0\n",
      "  %onnx::Gemm_332 : Float(*, 128, strides=[32768, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=1, onnx_name=\"Gather_253\"](%onnx::Gather_330, %onnx::Gather_331) # /tmp/ipykernel_18824/3039239234.py:16:0\n",
      "  %output : Float(*, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_254\"](%onnx::Gemm_332, %W.weight, %W.bias) # /home/jaekyungcho/anaconda3/envs/mlops/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When using PyTorch\n",
    "torch.onnx.export(\n",
    "    cola_model,  # model being run\n",
    "    (\n",
    "        input_sample[\"input_ids\"],\n",
    "        input_sample[\"attention_mask\"],\n",
    "    ),  # model input (or a tuple for multiple inputs)\n",
    "    \"models/model.onnx\",  # where to save the model\n",
    "    export_params=True,\n",
    "    opset_version=10,\n",
    "    verbose=True,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],  # the model's input names\n",
    "    output_names=[\"output\"],  # the model's output names\n",
    "    dynamic_axes={            # variable length axes\n",
    "        \"input_ids\": {0: \"batch_size\"},\n",
    "        \"attention_mask\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# When using PyTorch-lightning\n",
    "cola_model.to_onnx(\n",
    "  \"models/model.onnx\",             # where to save the model\n",
    "  input_sample,             # input samples with atleast batch size as 1\n",
    "  export_params=True,\n",
    "  opset_version=10,\n",
    "  input_names = [\"input_ids\", \"attention_mask\"],    # Input names\n",
    "  output_names = ['output'],  # Output names\n",
    "  dynamic_axes={            # variable length axes\n",
    "        \"input_ids\": {0: \"batch_size\"},\n",
    "        \"attention_mask\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX runtime\n",
    "\n",
    "ONNX runtime은 ONNX 모델의 inference engine 이다. Cuda 버전에 맞는 버전을 찾아 설치를 해주자. ([Cuda-ONNXruntime version table](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements:~:text=Install%20ORT.-,Requirements,-Please%20reference%20table))\n",
    "```bash\n",
    "python -m pip install onnxruntime-gpu==<version>\n",
    "```\n",
    "ONNX runtime은 서로 다른 OS와 HW(accelerator)에서 간편히 동작할 수 있도록 만들어졌다. \n",
    "가능한 모든 HW와 현재 플랫폼에서 사용 가능한 HW는 아래와 같이 확인 가능하다. 안타깝게도 연구실 서버는 Cuda 9.1이라서 onnxruntime-gpu를 지원하지는 않는 것 같다...ㅠㅠ\n",
    "```python\n",
    "from onnxruntime import  get_all_providers, get_available_providers\n",
    "print(get_all_providers())\n",
    "print(get_available_providers())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'MIGraphXExecutionProvider', 'ROCMExecutionProvider', 'OpenVINOExecutionProvider', 'DnnlExecutionProvider', 'NupharExecutionProvider', 'TvmExecutionProvider', 'VitisAIExecutionProvider', 'NnapiExecutionProvider', 'CoreMLExecutionProvider', 'ArmNNExecutionProvider', 'ACLExecutionProvider', 'DmlExecutionProvider', 'RknpuExecutionProvider', 'XnnpackExecutionProvider', 'CPUExecutionProvider']\n",
      "['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install onnxruntime, onnxruntime-gpu\n",
    "from onnxruntime import  get_all_providers, get_available_providers\n",
    "print(get_all_providers())\n",
    "print(get_available_providers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onnxruntime을 이용해 모델 inference를 해본다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.3588007,  0.3415024]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "onnx_model_path = 'models/model.onnx'\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "ort_inputs = {\n",
    "    \"input_ids\": input_sample[\"input_ids\"].numpy(),\n",
    "    \"attention_mask\": input_sample[\"attention_mask\"].numpy(),\n",
    "}\n",
    "output_name = None\n",
    "ort_output = ort_session.run(output_name, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time test\n",
    "\n",
    "일반적으로 2~3배 이상 속도 차이가 발생한다. 근데 구글에선 아무도 왜 빠른지에 의문을 품지는 않았다...(그냥 최적화를 잘 한걸지도...??) 사실 Pytorch는 꽤나 불필요한 연산들이 많이 진행될 것이다. gradient도 계산한 것을 전부 저장하고 있고 그러니까. 그런거 전부 날리면 3배 정도는 빠르게 할 수 있다는 것일테다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference time: 0.004585742950439453 sec\n",
      "PyTorch inference time: 0.015786170959472656 sec\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "ort_time = time()\n",
    "ort_output = ort_session.run(output_name, ort_inputs)\n",
    "print(\"ONNX inference time:\", time()-ort_time, \"sec\")\n",
    "\n",
    "pt_time = time()\n",
    "with torch.no_grad():\n",
    "    pt_output = cola_model(**input_sample)\n",
    "print(\"PyTorch inference time:\", time()-pt_time, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4003a536328e81fd4530ca84ec06d4fa87c59e1aebe2307b6b4e208c10633ca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
