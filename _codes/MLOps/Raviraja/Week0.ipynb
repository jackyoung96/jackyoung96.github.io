{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (1.7.7)\n",
      "Requirement already satisfied: torch in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (1.12.1)\n",
      "Requirement already satisfied: transformers in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (4.23.1)\n",
      "Requirement already satisfied: datasets in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (2.5.2)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (4.4.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (4.64.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (0.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (2.10.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (21.3)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (1.23.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pytorch_lightning) (2022.8.2)\n",
      "Requirement already satisfied: filelock in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: aiohttp in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pandas in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from datasets) (1.5.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp38-cp38-macosx_10_9_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (2.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.19.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.49.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (63.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pandas->datasets) (2022.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.2-cp38-cp38-macosx_10_9_x86_64.whl (34.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jackyoung96/opt/anaconda3/envs/mlops/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=f2cbf00b2e86338a5c6e418904947439edbf0994a014e11a111c518d532da0a8\n",
      "  Stored in directory: /Users/jackyoung96/Library/Caches/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.2 scipy-1.9.2 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pytorch_lightning torch transformers datasets sklearn\n",
    "from datasets import load_dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\", 'label': 1, 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "cola_dataset = load_dataset('glue','cola')\n",
    "print(cola_dataset)\n",
    "train_dataset = cola_dataset['train']\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "Pytorch lightning의 경우 Pytorch의 Dataloader와 유사한 DataModule을 사용한다.\n",
    "\n",
    "< 정의해야 하는 method >\n",
    "* prepare_data\n",
    "* setup\n",
    "* train_dataloader, val_dataloader, test_dataloader -> return DataLoader\n",
    "  \n",
    "< DataModule 안에서 수행되는 작업 >\n",
    "* Download / tokenize / process\n",
    "* Clean and save to disk\n",
    "* Load inside Dataset\n",
    "* Apply transforms (rotate, tokenize, etc…)\n",
    "* Wrap inside a DataLoader (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name) # Transformer (BERT) model\n",
    "\n",
    "    def prepare_data(self):\n",
    "        cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "        self.train_data = cola_dataset[\"train\"]\n",
    "        self.val_data = cola_dataset[\"validation\"]\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        # processing the data\n",
    "        return self.tokenizer(\n",
    "            example[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_data = self.train_data.map(self.tokenize_data, batched=True)\n",
    "            self.train_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "            self.val_data = self.val_data.map(self.tokenize_data, batched=True)\n",
    "            self.val_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "\n",
    "Pytorch에서 model을 만들떄 상속받았던 `torch.nn.Module`과 마찬가지로 Pytorch-lightning은 `pl.LightningModule`을 상속받는다. forward 만 정의해 주면 되었던 때와는 다르게, 몇 가지 method를 추가로 정의해 주어야 한다. ([Document](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html))\n",
    "\n",
    "< 정의 해야 할 methods >\n",
    "- forward -> return inference\n",
    "- training_step -> return loss\n",
    "- validation_step\n",
    "- test_step (optional)\n",
    "- configure_optimizers -> return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaModel(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", lr=1e-2):\n",
    "        super(ColaModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.num_classes = 2\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        h_cls = outputs.last_hidden_state[:, 0]\n",
    "        logits = self.W(h_cls)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        val_acc = accuracy_score(preds.cpu(), batch[\"label\"].cpu())\n",
    "        val_acc = torch.tensor(val_acc)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", val_acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Trainer\n",
    "\n",
    "DataModule과 Pytorch-lightning model은 Trainer를 이용해서 학습을 진행하게 된다(Tensorflow의 Session과 비슷한 접근 방법).  \n",
    "< Trainer 가 사용할 수 있는 options 예시 >\n",
    "- logging\n",
    "- gradient accumulation\n",
    "- half precision training\n",
    "- distributed computing\n",
    "  \n",
    "< Loggers >\n",
    "- TensorboardLogger\n",
    "- WandbLogger\n",
    "\n",
    "< Callbacks >\n",
    "[Documents](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_data = DataModule()\n",
    "cola_model = ColaModel()\n",
    "\n",
    "checkpoint_callbacks = [\n",
    "    ModelCheckpoint(dirpath=\"./models\", monitor=\"val_loss\", mode=\"min\"),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=True, mode=\"min\"),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=(1 if torch.cuda.is_available() else 0),\n",
    "    max_epochs=1,\n",
    "    fast_dev_run=False, # True: one batch training one validation -> for debugging\n",
    "    logger=pl.loggers.TensorBoardLogger(\"logs/\", name=\"cola\", version=1), # directory: logs/cola\n",
    "    # logger = pl.loggers.WandbLogger(name='cola',project='pytorchlightning')\n",
    "    callbacks=checkpoint_callbacks,\n",
    ")\n",
    "trainer.fit(cola_model, cola_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference module\n",
    "\n",
    "MLOps는 모델의 Training과 Inference의 모듈을 분리한다. 서버에서 학습이 진행되는 동안에도 모델을 freeze 하고 버전 관리를 하며 debuggin 할 수 있어야 하기 때문이다.  \n",
    "\n",
    "< 정의 해야 할 methods >\n",
    "- predict\n",
    "\n",
    "< Inference 내부에서 수행되는 작업 >\n",
    "- Load the trained model\n",
    "- Get the input\n",
    "- Convert the input in the required format\n",
    "- Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaPredictor:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        # loading the trained model\n",
    "        self.model = ColaModel.load_from_checkpoint(model_path)\n",
    "        # keep the model in eval mode\n",
    "        self.model.eval()\n",
    "        self.model.freeze()\n",
    "        self.processor = DataModule()\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "        self.lables = [\"unacceptable\", \"acceptable\"]\n",
    "\n",
    "    def predict(self, text):\n",
    "        # text => run time input\n",
    "        inference_sample = {\"sentence\": text}\n",
    "        # tokenizing the input\n",
    "        processed = self.processor.tokenize_data(inference_sample)\n",
    "        # predictions\n",
    "        logits = self.model(\n",
    "            torch.tensor([processed[\"input_ids\"]]),\n",
    "            torch.tensor([processed[\"attention_mask\"]]),\n",
    "        )\n",
    "        scores = self.softmax(logits[0]).tolist()\n",
    "        predictions = []\n",
    "        for score, label in zip(scores, self.lables):\n",
    "            predictions.append({\"label\": label, \"score\": score})\n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3b1c309fa0051d32391bd55013262f568df4108b46e8c7fd221bdaa1800d458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
